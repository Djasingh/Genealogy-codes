{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    # print vec1, vec2\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "    return Counter(WORD.findall(text))\n",
    "\n",
    "def get_similarity(a, b):\n",
    "    a = text_to_vector(a.strip().lower())\n",
    "    b = text_to_vector(b.strip().lower())\n",
    "\n",
    "    return get_cosine(a, b)\n",
    "\n",
    "get_similarity('L & L AIR CONDITIONING', 'L & L AIR CONDITIONING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"Python if possible.\"\n",
    "sent2 = \"Python if iii possible.\"\n",
    "sent3 = \"It can be so helpful to reinstall C++ if possible.\"\n",
    "sent4 = \"help It possible Python to re-install if might.\" # This has the same words as sent1 with a different order.\n",
    "sent5 = \"I love Python programming.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.edit_distance(sent1, sent2) #character label edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(obj, people):\n",
    "    for ent in obj:\n",
    "        for p in people.values:\n",
    "            yield (ent, p[14])\n",
    "for ent in get_entities(obj, people):\n",
    "    ne=nltk.edit_distance(ent[0].lower(), ent[1].lower())\n",
    "    if ne < 3:\n",
    "        print(ent[0]+'\\t'+ent[1]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Alan turing AND Alonzo Church'\n",
    "for url in search(query, stop=10):\n",
    "    if 'YouTube' not in url:\n",
    "        print(url)\n",
    "        a,b= google_scrape(url)\n",
    "        print('Title: {}'.format(a))\n",
    "        print('Text:{}'.format(b))\n",
    "        if 'Publications' in b:\n",
    "            print(\"==================================================\")\n",
    "            print('Publications:{}'.format(b.split('Publications')[1]))\n",
    "            print(\"==================================================\")\n",
    "        print(\"---------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"http://example.com/page\", params=dict(query=\"web scraping\", page=2))\n",
    "r.headers.get(\"content-type\", \"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    requests.get(\"http://example.com\")\n",
    "except requests.exceptions.RequestException:\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"David:Stephen_V=\"\n",
    "r = requests.get(\"https://dblp.uni-trier.de/pers/hd/d/\"+name)\n",
    "name=\"David:Stephen_V=\"\n",
    "\"https://dblp.uni-trier.de/pers/hd/d/\"+name\n",
    "r = requests.get(\"https://dblp.uni-trier.de/pers/\", params=dict(\n",
    "    query=\"David:Stephen_V\"\n",
    "))\n",
    "soup = bsoup(r.content, 'html.parser')\n",
    "title=soup.find('title').getText()\n",
    "\n",
    "for a in soup.find_all('article',class_='data'):\n",
    "    print(a.get_text())\n",
    "    \n",
    "name='Albright:Thomas_D='\n",
    "first=al.substring()\n",
    "r = requests.get(\"https://dblp.uni-trier.de/pers/hd/\"+a+al)\n",
    "soup = bsoup(r.content, 'html.parser')\n",
    "title=soup.find('title').getText()\n",
    "print(title)\n",
    "for a in soup.find_all('article',class_='data'):\n",
    "    print(a.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://hearingbrain.org/svd.CV.php')\n",
    "soup = bsoup(page.content, 'html.parser')\n",
    "title=soup.find('title').getText()\n",
    "for pub in soup.find_all(class_='bib'):\n",
    "    print(pub.get_text())\n",
    "    print(\"===================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_url='http://www.iitkgp.ac.in/department/CS/faculty/cs-abhij#resp-tab4'\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Firefox(options=options)\n",
    "driver.get(new_url)\n",
    "ele=driver.find_elements(By.CSS_SELECTOR,\"button.btn.btn-primary.btn-xs\")\n",
    "for x in range(len(ele)):\n",
    "    if ele[x].is_displayed():\n",
    "        driver.execute_script(\"arguments[0].click();\", ele[x])\n",
    "        time.sleep(1)\n",
    "page_source = driver.page_source\n",
    "soup = bsoup(page_source, 'html.parser')\n",
    "table=soup.find(\"div\",{\"id\":\"showAlumniMembersDetails\"})\n",
    "table_body = table.find('tbody')\n",
    "rows = table_body.find_all('tr')\n",
    "divs=rows[0].find('td').find_all('div')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
